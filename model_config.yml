model_name: "OPEA/Mistral-Small-3.1-24B-Instruct-2503-int4-AutoRound-awq-sym"
quantization: "awq"
gpu_memory_utilization: 0.7
tensor_parallel_size: null  # 例: nullにすると自動でGPU枚数に合わせる
batch_size: 32
max_tokens: 2048
max_model_len: 4096
trust_remote_code: True
dtype: "auto"
temperature: 0.9
top_p: 0.9